# Minimal Validation Sprint VAE Configuration
# Designed to complete quickly while proving training works

model:
  latent_dim: 32  # Smaller latent space for faster training
  group_norm_groups: 8

training:
  max_epochs: 2  # Just 2 epochs to prove it works
  batch_size: 4  # Very small batch size
  learning_rate: 1e-3
  weight_decay: 1e-5
  gradient_clip_val: 1.0
  beta_schedule: "constant"  # Simple schedule
  beta_max: 0.1  # Lower KL weight for stability
  beta_warmup_epochs: 0

data:
  train_split: "data/processed/splits/train_split.csv"
  val_split: "data/processed/splits/val_split.csv" 
  test_split: "data/processed/splits/test_split.csv"
  volumetric_cache_path: "data/processed/volumetric_cache_lmdb"
  num_workers: 0  # Single process
  pin_memory: false

checkpointing:
  monitor: "val_loss"
  mode: "min"
  save_top_k: 1
  save_last: true
  dirpath: "checkpoints/minimal_validation"
  filename: "minimal-vae-{epoch:02d}-{val_loss:.3f}"

# No early stopping for minimal run
# early_stopping:
#   monitor: "val_loss"
#   patience: 5
#   mode: "min"
#   min_delta: 0.001

logging:
  log_every_n_steps: 1  # Log every step
  val_check_interval: 1.0  # Check validation at the end of each epoch

# No W&B for minimal validation
# wandb:
#   project: "generative-brain-atlas"
#   name: "minimal-validation-vae"

hardware:
  accelerator: "cpu"
  devices: 1
  precision: "32"
  
# Trainer args to speed up minimal training  
limit_train_batches: 0.1  # Only use 10% of batches per epoch
limit_val_batches: 0.1    # Only validate on 10% of batches